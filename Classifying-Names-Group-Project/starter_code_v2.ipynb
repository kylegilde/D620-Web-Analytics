{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning Classifers with NLTK\n",
    "\n",
    "## CUNY DATA 620 Web Analytics\n",
    "\n",
    "### Fall 2018 Semester Class Project\n",
    "\n",
    "\n",
    "# Instructions\n",
    "\n",
    "- Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. \n",
    "\n",
    "\n",
    "- Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. \n",
    "\n",
    "\n",
    "- Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. \n",
    "\n",
    "\n",
    "- How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect? \n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Using the NLTK's `names` corpus, we will be demonstrating how to create and improve supervised classification models. The corpus contains 2 files called `female.txt` and `male.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "names.fileids() # confirm male and female txt files exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the male & female names, look at the first 20 entries for each and store them together in a variable called `people`. We will normalize the names by changing them to lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aamir', 'aaron', 'abbey', 'abbie', 'abbot', 'abbott', 'abby', 'abdel', 'abdul', 'abdulkarim', 'abdullah', 'abe', 'abel', 'abelard', 'abner', 'abraham', 'abram', 'ace', 'adair', 'adam']\n",
      "['abagael', 'abagail', 'abbe', 'abbey', 'abbi', 'abbie', 'abby', 'abigael', 'abigail', 'abigale', 'abra', 'acacia', 'ada', 'adah', 'adaline', 'adara', 'addie', 'addis', 'adel', 'adela']\n"
     ]
    }
   ],
   "source": [
    "# load male and female  name files from nltk.names; store in people list\n",
    "males, females = [n.lower() for n in names.words('male.txt')], [n.lower() for n in names.words('female.txt')] \n",
    "\n",
    "print([male for male in males[:20]])\n",
    "print([female for female in females[:20]])\n",
    "\n",
    "people = males + females"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 7944 names in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_people = len(people)\n",
    "n_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the variable `gender`, which will contain the gender labels for each of the names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make gender list\n",
    "gender = list(repeat('male', len(males))) + list(repeat('female', len(females)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we plot the frequency of the male and female names, we see that there is a class imbalance between the two labels. There are considerably more females than males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cbedeab5f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_counts = pd.Series(gender).value_counts()\n",
    "gender_counts.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, more than 60% are female. We will want to be cognizant of this class imbalance when we choose the metrics to evaluate the strength of our model. If we simply predicted that every name was female, we would be correct more than 60% of the time. We may also want to consider stratifying the training, development and testing data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cbee45e4e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender_counts.divide(n_people).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "## Initial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first1(word):\n",
    "    return word[0]\n",
    "def first2(word):\n",
    "    return word[0:2]\n",
    "def first3(word):\n",
    "    return word[0:3] if len(word) > 2 else word[0:2]\n",
    " \n",
    "def last1(word):\n",
    "    return word[-1]\n",
    "def last2(word):\n",
    "    return word[-2:]\n",
    "def last3(word):\n",
    "    return word[-3:] if len(word) > 2  else word[-2:]\n",
    "\n",
    "def vowel_count(word):\n",
    "    vowels = [letter for letter in word if letter in 'aeiou']\n",
    "    return len(vowels)\n",
    "\n",
    "initial_features = [len, first1, first2, first3, last1, last2, last3, vowel_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce features\n",
    "def gender_features(word, features):\n",
    "    \"\"\"\n",
    "    function returns dictionary of features\n",
    "        word: name to extract features from\n",
    "        args: list of functions\n",
    "               \n",
    "    \"\"\"\n",
    "    \n",
    "    gf = {}\n",
    "    # creates dictionary with the features\n",
    "    for feature in features:\n",
    "        gf[feature.__name__] = feature(word)\n",
    "\n",
    "    return gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aamir\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'len': 5,\n",
       " 'first1': 'a',\n",
       " 'first2': 'aa',\n",
       " 'first3': 'aam',\n",
       " 'last1': 'r',\n",
       " 'last2': 'ir',\n",
       " 'last3': 'mir',\n",
       " 'vowel_count': 3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify name, and argument list \n",
    "print(people[0])\n",
    "gender_features(people[0], initial_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Development & Test Sets\n",
    "\n",
    "Let's partition our data into 3 buckets. We will stratify each bucket in order to maintain our class imbalance and set the random state to 4.\n",
    "\n",
    "- First, let's set aside 500 observations that will not be used in training or development. We will use this teste set to evaluate the strength of the model.\n",
    "\n",
    "- Then, let's hold out another 500 observations to use as a development set to do error analysis.\n",
    "\n",
    "- Finally, we will use the remaining 6944 names to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside 500 samples for testing\n",
    "people_dev_train, people_test, gender_dev_train, gender_test = train_test_split(people, \n",
    "                                                                        gender, \n",
    "                                                                        test_size=500, \n",
    "                                                                        stratify=gender, \n",
    "                                                                        random_state=4)\n",
    "\n",
    "# set aside 500 samples for development\n",
    "people_train, people_devtest, gender_train, gender_devtest = train_test_split(people_dev_train, \n",
    "                                                                            gender_dev_train, \n",
    "                                                                            test_size=500, \n",
    "                                                                            stratify=gender_dev_train,\n",
    "                                                                            random_state=4)\n",
    "\n",
    "# list of tuples (name, gender)\n",
    "train_names = list(zip(people_train, gender_train))\n",
    "devtest_names = list(zip(people_devtest, gender_devtest))\n",
    "test_names = list(zip(people_test, gender_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will then apply our features to these 3 sets, keeping in mind that we will need to recreate these if we add new features to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(names, genders, features):\n",
    "    \"\"\"\n",
    "    function returns list of tuples (name features, gender)\n",
    "        names: list of names to extract features from\n",
    "        genders: list of gender values\n",
    "        features: list of feature functions           \n",
    "    \"\"\"    \n",
    "    return list(zip(map(lambda d: gender_features(d, features), names), genders))\n",
    "\n",
    "train_set  = create_features(people_train, gender_train, initial_features)\n",
    "devtest_set = create_features(people_devtest, gender_devtest, initial_features)\n",
    "test_set = create_features(people_test, gender_test, initial_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification\n",
    "\n",
    "Let's use the naive Bayes (NB) classifier to build our first model. This model derives its \"naiviete\" from its independence asssumption. NB assumes that all features are independent of one another, but features within real-world data often contain dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train naive bayes classifier \n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy between the training and development sets is fairly high at .858."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858\n"
     ]
    }
   ],
   "source": [
    "# classifer accuracy on validation set\n",
    "print(nltk.classify.accuracy(nb_classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the likelihood ratios of most important features so far. When the last 2 letters are 'na', the name is 93 times more often female than male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   last2 = 'na'           female : male   =     93.3 : 1.0\n",
      "                   last2 = 'ia'           female : male   =     51.8 : 1.0\n",
      "                   last2 = 'us'             male : female =     35.6 : 1.0\n",
      "                   last1 = 'a'            female : male   =     34.9 : 1.0\n",
      "                   last2 = 'sa'           female : male   =     34.2 : 1.0\n",
      "                   last2 = 'ld'             male : female =     33.9 : 1.0\n",
      "                   last1 = 'k'              male : female =     30.3 : 1.0\n",
      "                   last2 = 'do'             male : female =     27.2 : 1.0\n",
      "                   last3 = 'tta'          female : male   =     25.5 : 1.0\n",
      "                   last2 = 'rd'             male : female =     25.3 : 1.0\n",
      "                   last3 = 'ana'          female : male   =     24.7 : 1.0\n",
      "                   last2 = 'ta'           female : male   =     24.0 : 1.0\n",
      "                   last2 = 'io'             male : female =     23.9 : 1.0\n",
      "                   last2 = 'ra'           female : male   =     23.8 : 1.0\n",
      "                   last3 = 'ard'            male : female =     21.5 : 1.0\n",
      "                   last2 = 'rt'             male : female =     19.7 : 1.0\n",
      "                   last3 = 'nne'          female : male   =     17.9 : 1.0\n",
      "                  first2 = 'hu'             male : female =     17.2 : 1.0\n",
      "                   last2 = 'os'             male : female =     17.2 : 1.0\n",
      "                   last3 = 'son'            male : female =     15.8 : 1.0\n",
      "                   last1 = 'f'              male : female =     15.3 : 1.0\n",
      "                   last3 = 'old'            male : female =     15.0 : 1.0\n",
      "                   last3 = 'ita'          female : male   =     14.0 : 1.0\n",
      "                   last3 = 'dra'          female : male   =     13.5 : 1.0\n",
      "                   last3 = 'ria'          female : male   =     13.1 : 1.0\n",
      "                  first3 = 'tha'            male : female =     13.0 : 1.0\n",
      "                  first2 = 'ya'             male : female =     11.7 : 1.0\n",
      "                   last2 = 'ns'             male : female =     11.7 : 1.0\n",
      "                   last1 = 'p'              male : female =     11.2 : 1.0\n",
      "                   last1 = 'v'              male : female =     11.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# look at most informative features\n",
    "nb_classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at some of the model's misclassified names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual, prediction, name: \n",
      "\n",
      "('male', 'female', 'llewellyn')\n",
      "('female', 'male', 'rianon')\n",
      "('female', 'male', 'michell')\n",
      "('male', 'female', 'gerrit')\n",
      "('female', 'male', 'ruthy')\n",
      "('female', 'male', 'jan')\n",
      "('female', 'male', 'alyss')\n",
      "('male', 'female', 'moishe')\n",
      "('female', 'male', 'hazel')\n",
      "('female', 'male', 'mei')\n",
      "('male', 'female', 'michale')\n",
      "('female', 'male', 'elinor')\n",
      "('male', 'female', 'martyn')\n",
      "('male', 'female', 'herculie')\n",
      "('male', 'female', 'lindsey')\n",
      "('female', 'male', 'sharron')\n",
      "('female', 'male', 'terry')\n",
      "('female', 'male', 'nike')\n",
      "('female', 'male', 'izabel')\n",
      "('female', 'male', 'fran')\n",
      "('female', 'male', 'paige')\n",
      "('female', 'male', 'olwen')\n",
      "('female', 'male', 'clary')\n",
      "('male', 'female', 'jermaine')\n",
      "('female', 'male', 'tierney')\n",
      "('male', 'female', 'moise')\n",
      "('female', 'male', 'berty')\n",
      "('female', 'male', 'wallie')\n",
      "('male', 'female', 'seth')\n",
      "('female', 'male', 'quentin')\n",
      "('female', 'male', 'leigh')\n",
      "('male', 'female', 'kenneth')\n",
      "('male', 'female', 'augustine')\n",
      "('male', 'female', 'fidel')\n",
      "('male', 'female', 'cat')\n",
      "('female', 'male', 'penny')\n",
      "('female', 'male', 'tracy')\n",
      "('male', 'female', 'blare')\n",
      "('female', 'male', 'brear')\n",
      "('male', 'female', 'garcia')\n",
      "('male', 'female', 'salvatore')\n",
      "('female', 'male', 'ninon')\n",
      "('male', 'female', 'louis')\n",
      "('female', 'male', 'dorcas')\n",
      "('male', 'female', 'theodore')\n",
      "('female', 'male', 'maud')\n",
      "('female', 'male', 'lamb')\n",
      "('female', 'male', 'cherish')\n",
      "('male', 'female', 'ashby')\n",
      "('female', 'male', 'margery')\n",
      "('male', 'female', 'freddie')\n",
      "('female', 'male', 'gennifer')\n",
      "('female', 'male', 'christan')\n",
      "('male', 'female', 'ronnie')\n",
      "('female', 'male', 'allis')\n",
      "('female', 'male', 'remy')\n",
      "('female', 'male', 'phil')\n",
      "('female', 'male', 'jonis')\n",
      "('female', 'male', 'angel')\n",
      "('female', 'male', 'barbey')\n",
      "('male', 'female', 'eustace')\n",
      "('male', 'female', 'nathanial')\n",
      "('male', 'female', 'antoni')\n",
      "('female', 'male', 'marj')\n",
      "('male', 'female', 'granville')\n",
      "('female', 'male', 'harley')\n",
      "('female', 'male', 'nell')\n",
      "('male', 'female', 'scarface')\n",
      "('female', 'male', 'olympe')\n",
      "('male', 'female', 'guthrie')\n",
      "('female', 'male', 'tammy')\n"
     ]
    }
   ],
   "source": [
    "# look at names that were mis-classified\n",
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    #print(name)\n",
    "    prediction = nb_classifier.classify(gender_features(name, initial_features))\n",
    "    if prediction != tag:\n",
    "        errors.append((tag, prediction, name))\n",
    "\n",
    "print('actual, prediction, name: \\n')\n",
    "for x in errors:\n",
    "    print(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aamir\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'len': 5,\n",
       " 'first1': 'a',\n",
       " 'first2': 'aa',\n",
       " 'first3': 'aam',\n",
       " 'last1': 'r',\n",
       " 'last2': 'ir',\n",
       " 'last3': 'mir',\n",
       " 'vowel_count': 3,\n",
       " 'every_other2_beg': 'am',\n",
       " 'every_other3_beg': 'amr',\n",
       " 'every_other2_end': 'mr',\n",
       " 'every_other3_end': 'amr'}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def every_other2_beg(word):\n",
    "    return word[0] + word[2] if len(word) > 2 else word[0]\n",
    "def every_other3_beg(word): \n",
    "    return every_other2_beg(word) + word[4] if len(word) > 4 else every_other2_beg(word)\n",
    "\n",
    "# every other end\n",
    "def every_other2_end(word): \n",
    "    return word[-3] + word[-1] if len(word) > 2 else word[-1]\n",
    "def every_other3_end(word): \n",
    "    return word[-5] + every_other2_end(word) if len(word) > 4 else every_other2_end(word)\n",
    "    \n",
    "features_v2 = initial_features + [every_other2_beg, every_other3_beg, every_other2_end, every_other3_end]\n",
    "print(people[0])\n",
    "gender_features(people[0], features_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "people_train_v2, people_devtest_v2, gender_train_v2, gender_devtest_v2 = train_test_split(people_dev_train, \n",
    "                                                                            gender_dev_train, \n",
    "                                                                            test_size=500, \n",
    "                                                                            stratify=gender_dev_train,\n",
    "                                                                            random_state=5)\n",
    "\n",
    "# list of tuples (name, gender)\n",
    "train_names_v2 = list(zip(people_train_v2, gender_train_v2))\n",
    "devtest_names_v2 = list(zip(people_devtest_v2, gender_devtest_v2))\n",
    "\n",
    "# feature sets\n",
    "train_set_v2  = create_features(people_train_v2, gender_train_v2, features_v2)\n",
    "devtest_set_v2 = create_features(people_devtest_v2, gender_devtest_v2, features_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "Most Informative Features\n",
      "                   last2 = 'na'           female : male   =     94.1 : 1.0\n",
      "        every_other2_end = 'la'           female : male   =     79.5 : 1.0\n",
      "        every_other2_end = 'ea'           female : male   =     64.1 : 1.0\n",
      "        every_other2_end = 'ia'           female : male   =     44.8 : 1.0\n",
      "                   last2 = 'ia'           female : male   =     38.5 : 1.0\n",
      "                   last2 = 'ld'             male : female =     37.2 : 1.0\n",
      "                   last2 = 'us'             male : female =     35.6 : 1.0\n",
      "                   last1 = 'a'            female : male   =     33.6 : 1.0\n",
      "        every_other3_end = 'aia'          female : male   =     32.9 : 1.0\n",
      "                   last2 = 'sa'           female : male   =     32.6 : 1.0\n",
      "                   last1 = 'k'              male : female =     30.8 : 1.0\n",
      "                   last3 = 'nne'          female : male   =     29.8 : 1.0\n",
      "        every_other2_end = 'aa'           female : male   =     25.6 : 1.0\n",
      "                   last2 = 'rd'             male : female =     25.3 : 1.0\n",
      "                   last2 = 'do'             male : female =     25.0 : 1.0\n",
      "                   last2 = 'ta'           female : male   =     24.8 : 1.0\n",
      "                   last3 = 'ana'          female : male   =     24.2 : 1.0\n",
      "                   last3 = 'tta'          female : male   =     24.2 : 1.0\n",
      "                   last2 = 'io'             male : female =     23.9 : 1.0\n",
      "        every_other2_end = 'od'             male : female =     23.3 : 1.0\n",
      "        every_other2_end = 'ra'           female : male   =     22.4 : 1.0\n",
      "                   last2 = 'ra'           female : male   =     22.4 : 1.0\n",
      "                   last3 = 'ard'            male : female =     21.6 : 1.0\n",
      "                   last3 = 'vin'            male : female =     20.2 : 1.0\n",
      "                   last2 = 'rt'             male : female =     19.7 : 1.0\n",
      "        every_other2_end = 'da'           female : male   =     18.4 : 1.0\n",
      "        every_other2_end = 'sa'           female : male   =     17.8 : 1.0\n",
      "        every_other2_end = 'ad'             male : female =     17.7 : 1.0\n",
      "        every_other2_beg = 'kt'           female : male   =     17.3 : 1.0\n",
      "                  first2 = 'hu'             male : female =     17.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# train naive bayes classifier \n",
    "nb_classifier_v2 = nltk.NaiveBayesClassifier.train(train_set_v2)\n",
    "# classifer accuracy on validation set\n",
    "print(nltk.classify.accuracy(nb_classifier_v2, devtest_set_v2))\n",
    "# look at most informative features\n",
    "nb_classifier_v2.show_most_informative_features(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "http://www.nltk.org/howto/corpus.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled names:  202\n"
     ]
    }
   ],
   "source": [
    "# show number of mislabeled names \n",
    "print \"Mislabeled names: \", len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
